---
title: "R Notebook"
output: html_notebook
---
# Customer Segmentation using RFM Analysis (R)

**RFM (recency, frequency, monetary) analysis is a marketing technique used to determine quantitatively which customers are the best ones by examining **

* how recently a customer has purchased (recency), 
* how often they purchase (frequency), 
* and how much the customer spends (monetary).

https://help.synerise.com/use-cases/all-cases/_gfx/rfm1.png

 Identifying the most valuable RFM segments can capitalize on chance relationships in the data used for this analysis.
 

# Load libraries :
```{r}

library(data.table)
library(dplyr)
library(ggplot2)
#library(stringr)
#library(DT)
library(tidyr)
library(knitr)
library(rmarkdown)
library(lubridate)
```
 

#Data Loading :

```{r}
#data <- read.csv("E:/Project/CustomerSegmentataion/data.csv")

data <- read.csv("D:/VisualStudioCode/R/CustomerSegmentationusingR/Project_1_Customer_Segmentation_using_R/Project_CustomerSegmentationUsingR/data.csv")
data

data <- data.frame(data)
```

```{r}
summary(data)
```

# Data cleaning : 

```{r}
glimpse(data)
```

checking NA values : 
```{r}
sum(is.na(data))
```

Removing Negative values from Quantity : 
```{r}
data <- data %>% filter(Quantity>=0)
```


```{r}
sum(is.na(data))
```

Filtering the Dataframe : Removing NA values 
```{r}
data <- data %>% filter(!is.na(CustomerID))
```

```{r}
sum(is.na(data))
```

```{r}
summary(data)
```

No of customer records : 
```{r}
nrow(data)
```

Number Of countries : 
```{r}
length(unique(data$Country))
```

The custumers are from 37 different countries. Lets visualize this.

```{r}
#reorder the table and reset the factor to that ordering
data %>%
  group_by(Country) %>%                              # calculate the counts
  summarize(counts = n()) %>%
  arrange(counts) %>%                                # sort by counts
  mutate(Country = factor(Country, Country)) %>%     # reset factor
  ggplot(aes(x=Country, y=counts)) +                 # plot 
    geom_bar(stat="identity") +                      # plot histogram
    coord_flip()                                     # flip the coordinates
```
The goods are shipped to 38 unique countries. The majority of goods is shipped to the United Kingdom. After the United Kingdom, Germany, France and EIRE (=Ireland) are the most important countries.

# Feature Engineering :

Make a new variable called TotalPrice, this variable gives the total price for each entry

```{r}
data$TotalPrice <- data$Quantity * data$UnitPrice
data


```
```{r}
#range 
#range(data$InvoiceDate)
```



```{r}
data$InvoiceDateTime <- mdy_hm(data$InvoiceDate) #make datetime object
data$InvoiceDate <- ymd(date(data$InvoiceDateTime)) #make date variable
head(data)
```

```{r}
data$InvoiceYear <- year(data$InvoiceDate)
data$InvoiceMonth <- month(data$InvoiceDate,label=T)
data$InvoiceWeekday <- wday(data$InvoiceDate, label=T)
data$InvoiceHour <- hour(data$InvoiceDate)
```

Here we have the number of transactions per month for 2011.
```{r}
timedata <- data %>% 
  filter(InvoiceYear==2011) %>% 
  count(InvoiceMonth)  #count the number of invoices per month for 2011

ggplot(timedata, aes(InvoiceMonth, n)) +  #plot the number of invoices per day               
  geom_col() +
  labs(x="Month", y="Number of invoices")

```
It seems that the number of transactions is rising from September and the highest in November. In december the lowest number of transactions is performed.

```{r}
timedata <- data %>% 
  filter(InvoiceYear==2011) %>% 
  count(InvoiceWeekday)

ggplot(timedata, aes(InvoiceWeekday, n)) +  #plot the number of invoices per day               
    geom_col() +
  labs(x="Week", y="Number of invoices") 
```
Most transactions are placed on monday, tuesday, wednesday and thursday.

```{r}
timedata <- data %>% 
 filter(InvoiceYear==2011) %>% 
  count(InvoiceHour)

#ggplot(timedata, aes(InvoiceHour, n)) +  #plot the number of invoices per day               
    #geom_col() +
  #labs(x="hour", y="Number of invoices") 
#The most transactions are performed between 10 en 16:00 hours. At 12 hours the most transactions are performed.
```




##########################################################33

```{r}
retail <- data.frame(na.omit(df))
retail$InvoiceDate <- as.Date(retail$InvoiceDate, '%m/%d/%Y %H:%M')
range(retail$InvoiceDate)
```


```{r}
summary(retail)
```

```{r}
retail <- subset(retail, InvoiceDate >= "2010-12-09")
range(retail$InvoiceDate)
```


```{r}
table(retail$Country)
countries <- as.data.frame(table(retail$Country))
#names(countries)[names(countries) == 'Var1'] <- 'country'

#retail <- subset(retail, Country == "United Kingdom")

length(unique(retail$InvoiceNo))
length(unique(retail$CustomerID))

# Identify returns
retail$item.return <- grepl("C", retail$InvoiceNo, fixed=TRUE)
retail$purchase.invoice <- ifelse(retail$item.return=="TRUE", 0, 1)
table(retail$item.return)
table(retail$purchase.invoice)

```


# RFM : 

```{r}
customers <- as.data.frame(unique(retail$CustomerID))
names(customers) <- "CustomerID"
```

```{r}
# Recency #
###########

#retail$recency <- as.Date("2011-12-10") - retail$InvoiceDate
#data$InvoiceDateTime <- mdy_hm(data$InvoiceDate) #make datetime variable
#data$InvoiceDate <- ymd(date(data$InvoiceDate)) #make date variable

data$Recency <-  as.numeric(mdy("01-01-2012") - data$InvoiceDate)

r_data <- data %>% 
  group_by(CustomerID) %>% 
  summarize(Recency=min(Recency))

r_data

```

Recency
Recency was calculated as one of the features for the segmentation analysis. In this case recency has been calculated as follows, time of customer’s last purchase minus the last transaction date in days.


```{r}
# Frequency #
#############

#customer.invoices <- subset(retail, select = c("CustomerID","InvoiceNo", "purchase.invoice"))

f_data <- data %>% 
  group_by(CustomerID) %>%  
  count(Frequency=n_distinct(InvoiceNo)) %>%
  mutate(Frequency > 0)%>%
  select(CustomerID, Frequency ) # Remove customers who have not made any purchases in the past year


#customers <- subset(f_data, Frequency > 0)

f_data
```

Frequency of Purchase
Frequency was calculated counting the number of times a customer has made a transaction with the Online Retailer in a year. It is important to calculate the frequency of purchases, the online retailer wants it’s customers to buy as many times as possible, but the behavior of customers may be very different, some may a purchase a few times in bulk while other purchase low quantities frequently. The objective is to understand this behavior to serve them better.

Huge difference between the 3rd and maximum number of purcchases (7,812) Let’s investigate this further and visualize it in two different boxplots


```{r}
###############################
# Monetary Value of Customers #
###############################

# Total spent on each item on an invoice
#retail$Amount <- retail$Quantity * retail$UnitPrice
m_data <- data %>% 
  group_by(CustomerID) %>% 
  summarise(Monetary=sum(TotalPrice >0))

# Identify customers with negative monetary value numbers, as they were presumably returning purchases from the preceding year

m_data

```

Monetary Value
Finally, the last calculation to build before the cluster segmentation model is Monetary Value. This refers to the total sum of revenue generated by the user over the course of a year.

It has been estimated calculating the Unit Price and Quantity per transaction and grouping by CustomerID.
```{r}

MV_3Q <- m_data %>%
  filter( Monetary <= 15000)

MV_Outliers <- m_data %>%
  filter(Monetary > 15000)

# Visualizing a histogram of revenue generated by user
MV_3Q_Visz <- ggplot(MV_3Q, aes(Monetary)) +
  geom_histogram() +
  ggtitle('Revenue of Users - Below $15K') +
  ylab('Number of Users') +
  xlab('Revenue') +
  scale_x_continuous(labels = scales::dollar) +
  scale_y_continuous(labels = scales::comma)
print(MV_3Q_Visz)

# Visualizing histogram of Revenue Outliers
Outliers_Visz <- ggplot(m_data, aes(Monetary)) +
  geom_histogram() +
  ggtitle('High Revenue Users - Outliers') +
  ylab('Number of Users') +
  xlab('Revenue') +
  scale_x_continuous(labels = scales::dollar, breaks = c(50000, 100000, 150000, 200000, 250000, 300000, 350000)) +
  scale_y_continuous(labels = scales::comma)
print(Outliers_Visz)

```


Merging Recency, Frequency and Monetary Value. RFM
Time to start merging the dataset for the cluster segmentation. So far, there has been three features constructed for the model. Recency, Frequency and Monetary Value of each customer. The three of these variables are now linked to the respective CustomerID.

Combine these the data sets r_data, f_data and m_data


```{r}


new_data <- r_data %>% 
  full_join(m_data, by="CustomerID") %>% 
  full_join(f_data, by="CustomerID")

new_data
```


# Calculate RFM

**To implement the RFM analysis, we need to further process the data set in by the following steps:**


Now we have a new data set, containing four variables called 
1) customerID, 2)Recency, 3)Monatory and 4) Frequency. 

These four variables should be segmented in equal groups. Lets start with the first variable recency:


```{r}
#print(summary(customers$recency))
#kable(head(customers))

new_data$Recency_group <- cut(new_data$Recency, 
                              quantile(new_data$Recency, 
                              probs=seq(0,1,0.25)), 
                              ordered_result=T, 
                              include.lowest=T) # segment data into groups

new_data$Recency_group <- factor(new_data$Recency_group, 
                                 labels=c("very recent", "recent", "old", "oldest")) # rename levels

new_data
```


Now we can proceed with the variable called frequency. This variable will also be divided in four groups.

```{r}
table(new_data$Frequency)

```
Aas shown in the table above, it is not possible to use quantile to divide the population in four equal groups. This is because the majority of customers only places 1 or 2 orders (n=2305) and there are very few customers that place many orders. Lets try the following segmentation

1 order: n=1503 2-3 orders: n=1304 4-9 orders: n=1071 10 or more: n=341

```{r}
new_data$Frequency_group <- cut(new_data$Frequency, 
                              c(0,1,3,10,188), 
                              ordered_result=T) #segment into four groups

new_data$Frequency_group <- factor(new_data$Frequency_group, 
                                 labels=c("very rare", "rare", "frequent", "very frequent"))

new_data
```


Now proceed with the value monetary value

```{r}
new_data$Monetory_group <- cut(new_data$Monetary, 
                              quantile(new_data$Monetary, probs=seq(0,1,0.25)), 
                              ordered_result=T, include.lowest=T) #segment into groups

new_data$Monetory_group <- factor(new_data$Monetory_group, 
                                 labels=c("small", "medium", "large", "very large")) #rename levels
new_data
```

# Visualize results
We now have segmented our customers in different groups. Lets visualize this:

```{r}
ggplot(new_data, aes(Recency_group, Frequency_group)) +
  geom_count() +
  facet_grid(Monetory_group ~ .) +
  labs(x="Recency", y="Frequency", title="RFM analysis 2011") 
```




# Statistical Clustering - KMeans





