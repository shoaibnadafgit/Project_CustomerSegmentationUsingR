---
title: "R Notebook"
output: html_notebook
---


```{r}

#data <- read.csv("D://VisualStudioCode//R//CustomerSegmentationusingR//Project_CustomerSegmentat#ionUsingR//data.csv")
data <- read.csv("E:/Project/CustomerSegmentataion/data.csv")
data

df <- data.frame(data)
```
Get the structure  and summary of the data frame.
```{r}
typeof(df)
str(df)
summary(df)
```

# Customer Segmentation using RFM Analysis (R)

**RFM (recency, frequency, monetary) analysis is a marketing technique used to determine quantitatively which customers are the best ones by examining **

* how recently a customer has purchased (recency), 
* how often they purchase (frequency), 
* and how much the customer spends (monetary).

https://help.synerise.com/use-cases/all-cases/_gfx/rfm1.png

 Identifying the most valuable RFM segments can capitalize on chance relationships in the data used for this analysis.
 
# Load libraries :
 
```{r}
library(data.table)
library(dplyr)
library(ggplot2)
#library(stringr)
#library(DT)
library(tidyr)
library(knitr)
library(rmarkdown)
library(lubridate)

```


```{r}
glimpse(df)
```


```{r}
retail <- data.frame(na.omit(df))
retail$InvoiceDate <- as.Date(retail$InvoiceDate, '%m/%d/%Y %H:%M')
range(retail$InvoiceDate)
```

```{r}
summary(retail)
```

```{r}
retail <- subset(retail, InvoiceDate >= "2010-12-09")
range(retail$InvoiceDate)
```

```{r}
table(retail$Country)
countries <- as.data.frame(table(retail$Country))
names(countries)[names(countries) == 'Var1'] <- 'country'

retail <- subset(retail, Country == "United Kingdom")

length(unique(retail$InvoiceNo))
length(unique(retail$CustomerID))

# Identify returns
retail$item.return <- grepl("C", retail$InvoiceNo, fixed=TRUE)
retail$purchase.invoice <- ifelse(retail$item.return=="TRUE", 0, 1)
table(retail$item.return)
table(retail$purchase.invoice)
prop.table(table(retail$item.return))
```
```{r}
customers <- as.data.frame(unique(retail$CustomerID))
names(customers) <- "CustomerID"
```



```{r}
# Recency #
###########

retail$recency <- as.Date("2011-12-10") - as.Date(retail$InvoiceDate)

# remove returns so only consider the data of most recent *purchase*
temp <- subset(retail, purchase.invoice == 1)

# Obtain # of days since most recent purchase
recency <- aggregate(recency ~ CustomerID, data=temp, FUN=min, na.rm=TRUE)

# Add recency to customer data
customers <- merge(customers, recency, by="CustomerID", all=TRUE, sort=TRUE)
customers$recency <- as.numeric(customers$recency)
```

Recency
Recency was calculated as one of the features for the segmentation analysis. In this case recency has been calculated as follows, time of customer’s last purchase minus the last transaction date in days.

Based on the histogram, most of the clients have been active in the last 90-100 days. There are not benchmarks to compare this to, but 3 months of customer inactivity does not sound terrible, specially after it was discovered in the previous analysis that the company has not been acquired users as quick as it used to. However, some of this customers have over 140 days without making a single purchase.

Recency Statistics
The summary statistics below gives a goo rough undersating of the users behavior.

50% of the users are below 49 days of inactivity

Average of 3 months without making a single purchase.

Small group of customers that have not made a single transaction in over a year!

```{r}
summary(customers$recency)
hist(customers$recency)
```



```{r}
# Frequency #
#############

customer.invoices <- subset(retail, select = c("CustomerID","InvoiceNo", "purchase.invoice"))
customer.invoices <- customer.invoices[!duplicated(customer.invoices), ]
customer.invoices <- customer.invoices[order(customer.invoices$CustomerID),]
row.names(customer.invoices) <- NULL

# Number of invoices/year (purchases only)
annual.invoices <- aggregate(purchase.invoice ~ CustomerID, data=customer.invoices, FUN=sum, na.rm=TRUE)
names(annual.invoices)[names(annual.invoices)=="purchase.invoice"] <- "frequency"

# Add # of invoices to customers data
customers <- merge(customers, annual.invoices, by="CustomerID", all=TRUE, sort=TRUE)

range(customers$frequency)
table(customers$frequency)

# Remove customers who have not made any purchases in the past year
customers <- subset(customers, frequency > 0)

```


Frequency of Purchase
Frequency was calculated counting the number of times a customer has made a transaction with the Online Retailer in a year. It is important to calculate the frequency of purchases, the online retailer wants it’s customers to buy as many times as possible, but the behavior of customers may be very different, some may a purchase a few times in bulk while other purchase low quantities frequently. The objective is to understand this behavior to serve them better.

Frequency Statistics
Diving into how often the customers purchase from the online retailer.

Average of 90 transactions a year

75% of users have less than 100 purchases a year.

Huge difference between the 3rd and maximum number of purcchases (7,812) Let’s investigate this further and visualize it in two different boxplots.

```{r}
summary(customers$frequency)
boxplot(customers$CustomerID, xlab = "CustomeId" , ylab = "No of purchese per customer")
boxplot(customers$frequency , xlab = "frequency" , ylab = "No of purchese per customer")
#densityplot(customers$frequency)
```


```{r}
###############################
# Monetary Value of Customers #
###############################

# Total spent on each item on an invoice
retail$Amount <- retail$Quantity * retail$UnitPrice

# Aggregated total sales to customer
annual.sales <- aggregate(Amount ~ CustomerID, data=retail, FUN =sum, na.rm=TRUE)
names(annual.sales)[names(annual.sales)=="Amount"] <- "monetary"

# Add monetary value to customers dataset
customers <- merge(customers, annual.sales, by="CustomerID", all.x=TRUE, sort=TRUE)

# Identify customers with negative monetary value numbers, as they were presumably returning purchases from the preceding year
```

Finally, the last calculation to build before the cluster segmentation model is Monetary Value. This refers to the total sum of revenue generated by the user over the course of a year.

It has been estimated calculating the Unit Price and Quantity per transaction and grouping by CustomerID.

Monetary Value Statistics
There are customers who have Let’s visualize them in two plots like it was done previously.

There seems to be customers with negative revenue, apparently there are negative numbers in the price column. It could suggest purchase returns, this is an important assumption as we keep working on the segmentation.



```{r}
summary(customers$monetary)
#hist(customers$monetary, main = NULL, labels = TRUE, las = 1, cex.lab = 1.1, cex.axis = 1.1, col = "blue")
#customers$monetary <- ifelse(customers$monetary < 0, 0, customers$monetary) # reset negative numbers to zero
#hist(customers$monetary, labels = TRUE, type = "count", breaks = 10, las = 1, col = "blue" )

MV_3Q <- customers %>%
  filter(monetary <= 15000)

MV_Outliers <- customers %>%
  filter(monetary > 15000)

# Visualizing a histogram of revenue generated by user
MV_3Q_Visz <- ggplot(MV_3Q, aes(monetary)) +
  geom_histogram() +
  ggtitle('Revenue of Users - Below $15K') +
  ylab('Number of Users') +
  xlab('Revenue') +
  scale_x_continuous(labels = scales::dollar) +
  scale_y_continuous(labels = scales::comma)
print(MV_3Q_Visz)

# Visualizing histogram of Revenue Outliers
Outliers_Visz <- ggplot(customers, aes(monetary)) +
  geom_histogram() +
  ggtitle('High Revenue Users - Outliers') +
  ylab('Number of Users') +
  xlab('Revenue') +
  scale_x_continuous(labels = scales::dollar, breaks = c(50000, 100000, 150000, 200000, 250000, 300000, 350000)) +
  scale_y_continuous(labels = scales::comma)
print(Outliers_Visz)

```

```{r}
####################
# 80% and 20% rule #
####################

customers <- customers[order(-customers$monetary),]

# Apply Pareto Principle (80/20 Rule)
pareto.cutoff <- 0.8 * sum(customers$monetary)
# customers <- customers[,!customers$cumsum]
customers$pareto <- ifelse(cumsum(customers$monetary) <= pareto.cutoff, "Top 20%", "Bottom 80%")
customers$pareto <- factor(customers$pareto, levels=c("Top 20%", "Bottom 80%"), ordered=TRUE)
levels(customers$pareto)
round(prop.table(table(customers$pareto)), 2)

customers <- customers[order(customers$CustomerID),]
```

Merging Recency, Frequency and Monetary Value. RFM
Time to start merging the dataset for the cluster segmentation. So far, there has been three features constructed for the model. Recency, Frequency and Monetary Value of each customer. The three of these variables are now linked to the respective CustomerID.

Below,the Users RFM table, this table includes each CustomerID and their respective RFM features. The information in this table will be used for the Customer Segmentation.


```{r}
Users_RFM <- merge(recency,customers$frequency) # Merging Recency and Frequency
Users_RFM <- merge(Users_RFM, customers$monetary) # Merging Monetary Value
DT::datatable((Users_RFM),
              rownames = FALSE,
              options = list(
                pageLength = 10))

```


# Calculate RFM

**To implement the RFM analysis, we need to further process the data set in by the following steps:**

>> Find the most recent date for each ID and calculate the days to the now or some other date, to get the Recency data

>> Calculate the quantity of translations of a customer, to get the Frequency data
Sum the amount of money a customer spent and divide it by Frequency, to get the amount per transaction on average, that is the Monetary data.


Note : (Data currency is monetary value assigned to data to identify its financial significance to an organization. Once the monetary value of data assets is identified, it may be used as the unit of exchange in a transaction, either as the sole payment or in combination with money.) 

```{r}
print(summary(customers$recency))
kable(head(customers))

```




# Data Preprocessing
Because the data isn't normally distributed, so i transform the data with logarithmic transformation and z-score standardization.

```{r}
###################
# preprocess data #
###################

# Log-transform positively-skewed variables
customers$recency.log <- log(customers$recency)
customers$frequency.log <- log(customers$frequency)
customers$monetary.log <- customers$monetary + 0.1 # can't take log(0), so add a small value to remove zeros
customers$monetary.log <- log(customers$monetary.log)
customers <- customers[complete.cases(customers), ]

# Z-scores
customers$recency.z <- scale(customers$recency.log, center=TRUE, scale=TRUE)
customers$frequency.z <- scale(customers$frequency.log, center=TRUE, scale=TRUE)
customers$monetary.z <- scale(customers$monetary.log, center=TRUE, scale=TRUE)

##################
# visualize data #
##################

library(ggplot2)
library(scales)

# Original scale
scatter.1 <- ggplot(customers, aes(x = frequency, y = monetary))
scatter.1 <- scatter.1 + geom_point(aes(colour = recency, shape = pareto))
scatter.1 <- scatter.1 + scale_shape_manual(name = "80/20 Designation", values=c(17, 16))
scatter.1 <- scatter.1 + scale_colour_gradient(name="Recency\n(Days since Last Purchase))")
scatter.1 <- scatter.1 + scale_y_continuous(label=dollar)
scatter.1 <- scatter.1 + xlab("Frequency (Number of Purchases)")
scatter.1 <- scatter.1 + ylab("Monetary Value of Customer (Annual Sales)")
scatter.1

# Log-transformed
scatter.2 <- ggplot(customers, aes(x = frequency.log, y = monetary.log))
scatter.2 <- scatter.2 + geom_point(aes(colour = recency.log, shape = pareto))
scatter.2 <- scatter.2 + scale_shape_manual(name = "80/20 Designation", values=c(17, 16))
scatter.2 <- scatter.2 + scale_colour_gradient(name="Log-transformed Recency")
scatter.2 <- scatter.2 + xlab("Log-transformed Frequency")
scatter.2 <- scatter.2 + ylab("Log-transformed Monetary Value of Customer")
scatter.2
```




```{r}
#####################
# Handling Outliers #
#####################

# How many customers are represented by the two data points in the lower left-hand corner of the plot? 18
delete <- subset(customers, monetary.log < 0)
no.value.custs <- unique(delete$CustomerID)
delete2 <- subset(retail, CustomerID %in% no.value.custs)
delete2 <- delete2[order(delete2$CustomerID, delete2$InvoiceDate),]
customers$recency.z <- as.numeric(customers$recency.z)
customers$frequency.z <- as.numeric(customers$frequency.z)
customers$monetary.z <- as.numeric(customers$monetary.z)
# Scaled variables
scatter.3 <- ggplot(customers, aes(x = customers$frequency.z, y = customers$monetary.z))
scatter.3 <- scatter.3 + geom_point(aes(colour = recency.z, shape = pareto))
scatter.3 <- scatter.3 + scale_shape_manual(name = "80/20 Designation", values=c(17, 16))
scatter.3 <- scatter.3 + scale_colour_gradient(name="Z-scored Recency")
scatter.3 <- scatter.3 + xlab("Z-scored Frequency")
scatter.3 <- scatter.3 + ylab("Z-scored Monetary Value of Customer")
scatter.3
```


# Clustering :


```{r}
###########################################
# Determine number of cluster/run k-means #
###########################################

# subset only rfm features
preprocessed <- customers[,9:11]

j <- 10 # specify the maximum number of clusters you want to try out

models <- data.frame(k=integer(),
                     tot.withinss=numeric(),
                     betweenss=numeric(),
                     totss=numeric(),
                     rsquared=numeric())

for (k in 1:j ) {
  
  print(k)
  
  # Run kmeans
  # nstart = number of initial configurations; the best one is used
  output <- kmeans(preprocessed, centers = k, nstart = 20)
  # $iter will return the iteration used for the final model
  
  # Add cluster membership to customers dataset
  var.name <- paste("cluster", k, sep="_")
  customers[,(var.name)] <- output$cluster
  customers[,(var.name)] <- factor(customers[,(var.name)], levels = c(1:k))
  
  # Graph clusters
  cluster_graph <- ggplot(customers, aes(x = frequency.z, y = monetary.z))
  cluster_graph <- cluster_graph + geom_point(aes(colour = customers[,(var.name)]))
  colors <- c('red','orange','green3','deepskyblue','blue','darkorchid4','violet','pink1','tan3','black')
  cluster_graph <- cluster_graph + scale_colour_manual(name = "Cluster Group", values=colors)
  cluster_graph <- cluster_graph + xlab("Z-transformed Frequency")
  cluster_graph <- cluster_graph + ylab("Z-transformed Monetary Value of Customer")
  title <- paste("k-means Cluster dengan", k, sep=" ")
  title <- paste(title, "Clusters", sep=" ")
  cluster_graph <- cluster_graph + ggtitle(title)
  print(cluster_graph)
  
  # Cluster centers in original metrics
  library(plyr)
  print(title)
  cluster_centers <- ddply(customers, .(customers[,(var.name)]), summarize,
                           monetary=round(mean(monetary),2),# use median b/c this is the raw, heavily-skewed data
                           frequency=round(mean(frequency),1),# but this is k_means, so we use the mean
                           recency=round(mean(recency), 0))
  names(cluster_centers)[names(cluster_centers)=="customers[, (var.name)]"] <- "Cluster"
  print(cluster_centers)
  cat("\n")
  cat("\n")
  
  # Collect model information
  models[k,("k")] <- k
  models[k,("tot.withinss")] <- output$tot.withinss # the sum of all within sum of squares
  models[k,("betweenss")] <- output$betweenss
  models[k,("totss")] <- output$totss # betweenss + tot.withinss
  models[k,("rsquared")] <- round(output$betweenss/output$totss, 3) # percentage of variance explained by cluster membership
  assign("models", models, envir = .GlobalEnv)
  
  # remove(output, var.name, cluster_graph, cluster_centers, title, colors)
  
}
```


```{r}
output1 <- kmeans(preprocessed, centers = 1)
output2 <- kmeans(preprocessed, centers = 2)
output3 <- kmeans(preprocessed, centers = 3)
output4 <- kmeans(preprocessed, centers = 4)
output5 <- kmeans(preprocessed, centers = 5)
output6 <- kmeans(preprocessed, centers = 6)
output7 <- kmeans(preprocessed, centers = 7)
output8 <- kmeans(preprocessed, centers = 8)
output9 <- kmeans(preprocessed, centers = 9)
output10 <- kmeans(preprocessed, centers = 10)
```



```{r}
library(factoextra)
output1$size
output1$centers

output2$size
output2$centers

output3$size
output3$centers

output4$size
output4$centers

output5$size
output5$centers

output6$size
output6$centers

output7$size
output7$centers

output8$size
output8$centers

output9$size
output9$centers

output10$size
output10$centers

# with factoextra
fviz_cluster(output2, data = preprocessed, stand = FALSE,
                     main = paste("k-means Solution with k = 2"),
                     choose.vars = c("frequency.z", "monetary.z"),
                     star.plot = FALSE, 
                     show.clust.cent = TRUE, 
                     geom = "point",palette = "jco", ggtheme = theme_minimal())

# with factoextra
fviz_cluster(output5, data = preprocessed, stand = FALSE,
                     main = paste("k-means Solution with k = 5"),
                     choose.vars = c("frequency.z", "monetary.z"),
                     star.plot = FALSE, 
                     show.clust.cent = TRUE, 
                     geom = "point",palette = "jco", ggtheme = theme_minimal())
```



#The Best "k"

```{r}
# Graph variance explained by number of clusters
r2_graph <- ggplot(models, aes(x = k, y = rsquared))
r2_graph <- r2_graph + geom_point() + geom_line() + geom_text(aes(label = models$rsquared),hjust=1.15, vjust="outward")
r2_graph <- r2_graph + scale_y_continuous(labels = scales::percent)
r2_graph <- r2_graph + scale_x_continuous(breaks = 1:j)
r2_graph <- r2_graph + xlab("k (Number of Clusters)")
r2_graph <- r2_graph + ylab("Variance Explained")
r2_graph

# with factoextra
fviz_nbclust(preprocessed, kmeans, method = "wss") +
  geom_vline(xintercept = 2, linetype = 2)

# Graph within sums of squares by number of clusters
# Look for a "bend" in the graph, as with a scree plot
ss_graph <- ggplot(models, aes(x = k, y = tot.withinss))
ss_graph <- ss_graph + geom_point() + geom_line() + geom_text(aes(label = round(models$tot.withinss, 2)),hjust=0, vjust="inward")
ss_graph <- ss_graph + scale_x_continuous(breaks = 1:j)
ss_graph <- ss_graph + scale_y_continuous(labels = scales::comma)
ss_graph <- ss_graph + xlab("k (Number of Clusters)")
ss_graph <- ss_graph + ylab("Total Within SS")
ss_graph
```

